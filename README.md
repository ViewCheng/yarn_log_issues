# yarn_log_issues

Backgroud
======
在通过generic方式的数据传输下，我发现少了部分数据。但是job status是成功的。  

Thinking
=====

Schema issues
---

我的第一反应，是不是schema有问题，所以导致我们的数据给过滤掉了。因此我把成功的数据和       
和失败的数据各自下载了一部分在本地，在通过我本地自己的脚本进行测试，结果是都可以拿到  
因此证明schema并没有问题。

Jar issues
-----

基于第一点，我想会不会是系统并没有读取我们的schema。在我们的运行环境中有两次，一处是build1的打包，一次是node的运行  
因此我分别在这两处进行校正这一个job，实际情况是，都有我们自己的schema。  

此刻可能出现的问题就是config的问题，是不是我们的elt部门在某处有特别的过滤定义。初步看下来可以  
是没有这样的。 

YARN
---- 

这就非常奇怪了，因为一开始job是成功的，所以我并没有第一时间看yarn log，基于排除了所有可能，剩下的就是答案的原则   
我分别进入单个executor进行查看log。我发现，原来里面是有out of memory的情况，不过被系统给ignore了。导致有些块   
缺失了，也没有报错。并且由于系统认定不算失败，所以并没有进行自动扩容。   

所以我进入node的配置里，把memory扩到了16g然后进行提交。最后log里显示了所有失败的数据，属于modelling无法提交。  
然后我对大部分无法通过的数据进行了分析在加上log，我怀疑是modelling此处配置，因此定位在找到源代码，发现了是legid的问题。   
